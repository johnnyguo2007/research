{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cftime\n",
    "\n",
    "# Set the path to the NetCDF file\n",
    "netcdf_file = '/Trex/case_results/i.e215.I2000Clm50SpGs.hw_production.02/research_results/hw95_summary/i.e215.I2000Clm50SpGs.hw_production.02.clm2.h1.hwdaysOnly.nc'\n",
    "\n",
    "# Set the output directory\n",
    "output_dir = '/Trex/case_results/i.e215.I2000Clm50SpGs.hw_production.02/research_results/hw95_summary'\n",
    "\n",
    "summary_dir = '/Trex/case_results/i.e215.I2000Clm50SpGs.hw_production.02/research_results/summary'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset(netcdf_file)\n",
    "\n",
    "# Select the variables we want to include\n",
    "variables = ['TSA', 'TSA_U', 'TSA_R', 'TREFMXAV_R', 'HW']\n",
    "ds_subset = ds[variables]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = ds_subset.to_dataframe().reset_index()\n",
    "\n",
    "# Drop rows where TSA_U is missing\n",
    "df = df.dropna(subset=['TSA_U'])\n",
    "\n",
    "# Drop rows where TREFMXAV_R\n",
    "df = df.dropna(subset=['TREFMXAV_R']) # this will remove 19850101 data\n",
    "\n",
    "# Convert cftime to pandas datetime\n",
    "def convert_cftime_to_datetime(ct):\n",
    "    return pd.Timestamp(ct.year, ct.month, ct.day)\n",
    "\n",
    "df['time'] = df['time'].apply(convert_cftime_to_datetime)\n",
    "\n",
    "\n",
    "loc_id_path = os.path.join(summary_dir, 'location_IDs.nc')\n",
    "location_ds = xr.open_dataset(loc_id_path)\n",
    "location_df = location_ds.to_dataframe().reset_index()\n",
    "\n",
    "# Merge the location_df with the local_hour_adjusted_df\n",
    "df = pd.merge(df, location_df, on=['lat', 'lon'], how='left')\n",
    "\n",
    "# Sort the DataFrame\n",
    "df = df.sort_values(['location_ID', 'time'])\n",
    "\n",
    "# Save the DataFrame as a feather file\n",
    "output_file = os.path.join(output_dir, 'hw_data.feather')\n",
    "df.to_feather(output_file)\n",
    "\n",
    "print(f\"Data has been saved to {output_file}\")\n",
    "\n",
    "# Print some information about the resulting DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print unique lat-lon pairs\n",
    "unique_locations = df[['lat', 'lon']].drop_duplicates()\n",
    "print(f\"\\nNumber of unique lat-lon pairs: {len(unique_locations)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique lat-lon pairs where HW = 1\n",
    "hw_locations = df[df['HW'] == 1][['lat', 'lon']].drop_duplicates()\n",
    "hw_location_count = len(hw_locations)\n",
    "\n",
    "print(f\"Number of unique lat-lon pairs with HW = 1: {hw_location_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add location_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find row NaN on TREFMAXV_R\n",
    "t_nan_dates =pd.DataFrame(df[df['TREFMXAV_R'].isnull()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_nan_dates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = t_nan_dates.groupby('location_ID').filter(lambda x: len(x) == 1).groupby('location_ID').agg(\n",
    "    first_time=('time', 'first'),\n",
    "    count=('time', 'size')\n",
    ")\n",
    "\n",
    "result = result[result['first_time'] > '1985-01-01']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb \n",
    "\n",
    "nan_dates = duckdb.query(\n",
    "    \"\"\"\n",
    "    PRAGMA threads=4;\n",
    "    SELECT location_ID, COUNT(*) AS count, min(time) \n",
    "    FROM df \n",
    "    Where time > '1985-01-01' and TREFMXAV_R is NULL \n",
    "    GROUP BY location_ID  \n",
    "    having count > 1\n",
    "    \"\"\"\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['location_ID'] == 14825) & df['TREFMXAV_R'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\n",
    "    \"\"\"\n",
    "    SELECT location_ID, COUNT(*) AS count\n",
    "    FROM df \n",
    "    group by location_ID\n",
    "    order by count desc\n",
    "    \"\"\"\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df = df.dropna(subset=['TREFMXAV_R'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
