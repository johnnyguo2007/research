{
 "cells": [
  {
   "cell_type": "code",
   "id": "adcc6087f5cd7c2b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:28:15.222049Z",
     "start_time": "2024-04-11T12:28:14.954938Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  3: Load local_hour_adjusted_variables",
   "id": "1cf190d283e10258"
  },
  {
   "cell_type": "code",
   "id": "8a5ff8a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T12:36:19.939894Z",
     "start_time": "2024-04-11T12:36:17.904946Z"
    }
   },
   "source": [
    "summary_dir = '/Trex/case_results/i.e215.I2000Clm50SpGs.hw_production.02/research_results/summary'\n",
    "\n",
    "# merged_feather_path = os.path.join(summary_dir, 'local_hour_adjusted_variables.feather')\n",
    "merged_feather_path = os.path.join(summary_dir, 'local_hour_adjusted_variables_with_location_ID.feather')\n",
    "\n",
    "local_hour_adjusted_df = pd.read_feather(merged_feather_path)\n",
    "local_hour_adjusted_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58245960 entries, 0 to 58245959\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   lat           float32       \n",
      " 1   lon           float32       \n",
      " 2   time          datetime64[ns]\n",
      " 3   UHI           float32       \n",
      " 4   UWBI          float32       \n",
      " 5   WIND          float32       \n",
      " 6   RAIN          float32       \n",
      " 7   SNOW          float32       \n",
      " 8   HW            float64       \n",
      " 9   Q2M_R         float32       \n",
      " 10  Q2M_U         float32       \n",
      " 11  VAPOR_PRES_R  float32       \n",
      " 12  VAPOR_PRES_U  float32       \n",
      " 13  hour          int32         \n",
      " 14  month         int32         \n",
      " 15  year          int32         \n",
      " 16  UHI_avg       float32       \n",
      " 17  UWBI_avg      float32       \n",
      " 18  UHI_diff      float32       \n",
      " 19  UWBI_diff     float32       \n",
      " 20  local_time    datetime64[ns]\n",
      " 21  local_hour    int32         \n",
      " 22  location_ID   int64         \n",
      "dtypes: datetime64[ns](2), float32(15), float64(1), int32(4), int64(1)\n",
      "memory usage: 5.9 GB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T12:35:19.818574Z",
     "start_time": "2024-04-11T12:35:19.806532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "local_hour_adjusted_df.rename(columns=lambda x: x.replace('UBWI', 'UWBI'), inplace=True)\n",
    "local_hour_adjusted_df.info()\n",
    "var_with_id_path = os.path.join(summary_dir, 'local_hour_adjusted_variables_with_location_ID.feather')\n",
    "local_hour_adjusted_df.to_feather(var_with_id_path)\n",
    "'''"
   ],
   "id": "6658b5bb4d5baa37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58245960 entries, 0 to 58245959\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   lat           float32       \n",
      " 1   lon           float32       \n",
      " 2   time          datetime64[ns]\n",
      " 3   UHI           float32       \n",
      " 4   UWBI          float32       \n",
      " 5   WIND          float32       \n",
      " 6   RAIN          float32       \n",
      " 7   SNOW          float32       \n",
      " 8   HW            float64       \n",
      " 9   Q2M_R         float32       \n",
      " 10  Q2M_U         float32       \n",
      " 11  VAPOR_PRES_R  float32       \n",
      " 12  VAPOR_PRES_U  float32       \n",
      " 13  hour          int32         \n",
      " 14  month         int32         \n",
      " 15  year          int32         \n",
      " 16  UHI_avg       float32       \n",
      " 17  UWBI_avg      float32       \n",
      " 18  UHI_diff      float32       \n",
      " 19  UWBI_diff     float32       \n",
      " 20  local_time    datetime64[ns]\n",
      " 21  local_hour    int32         \n",
      " 22  location_ID   int64         \n",
      "dtypes: datetime64[ns](2), float32(15), float64(1), int32(4), int64(1)\n",
      "memory usage: 5.9 GB\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T12:35:44.363745Z",
     "start_time": "2024-04-11T12:35:35.378199Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "d5a76eedea885742",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T12:30:40.639098Z",
     "start_time": "2024-04-11T12:30:40.627278Z"
    }
   },
   "cell_type": "code",
   "source": "local_hour_adjusted_df.info()",
   "id": "b8b564a108f5ecbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58245960 entries, 0 to 58245959\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   lat           float32       \n",
      " 1   lon           float32       \n",
      " 2   time          datetime64[ns]\n",
      " 3   UHI           float32       \n",
      " 4   UBWI          float32       \n",
      " 5   WIND          float32       \n",
      " 6   RAIN          float32       \n",
      " 7   SNOW          float32       \n",
      " 8   HW            float64       \n",
      " 9   Q2M_R         float32       \n",
      " 10  Q2M_U         float32       \n",
      " 11  VAPOR_PRES_R  float32       \n",
      " 12  VAPOR_PRES_U  float32       \n",
      " 13  hour          int32         \n",
      " 14  month         int32         \n",
      " 15  year          int32         \n",
      " 16  UHI_avg       float32       \n",
      " 17  UBWI_avg      float32       \n",
      " 18  UHI_diff      float32       \n",
      " 19  UBWI_diff     float32       \n",
      " 20  local_time    datetime64[ns]\n",
      " 21  local_hour    int32         \n",
      " 22  location_ID   int64         \n",
      "dtypes: datetime64[ns](2), float32(15), float64(1), int32(4), int64(1)\n",
      "memory usage: 5.9 GB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  3.1: add location_id to the local_hour_adjusted_df",
   "id": "b5a64789dab23d30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "# Load the NetCDF file\n",
    "one_simu_result_monthly_file = '/Trex/case_results/i.e215.I2000Clm50SpGs.hw_production.02/sim_results/monthly/i.e215.I2000Clm50SpGs.hw_production.02.clm2.h0.1985-01.nc'\n",
    "ds = xr.open_dataset(one_simu_result_monthly_file)\n",
    "\n",
    "# Extract latitude and longitude values\n",
    "lat_values = ds['lat'].values\n",
    "lon_values = ds['lon'].values\n",
    "\n",
    "# Create a MultiIndex from the latitude and longitude values\n",
    "multi_index = pd.MultiIndex.from_product([lat_values, lon_values], names=['lat', 'lon'])\n",
    "\n",
    "# Create a DataFrame with the flattened index (location_ID)\n",
    "location_df = pd.DataFrame(index=multi_index).reset_index()\n",
    "location_df['location_ID'] = np.arange(len(location_df))\n",
    "\n",
    "# Merge the location_df with the local_hour_adjusted_df\n",
    "local_hour_adjusted_df = pd.merge(local_hour_adjusted_df, location_df, on=['lat', 'lon'], how='left')\n",
    "'''\n"
   ],
   "id": "f612e5f97219d7b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "# Save the local_hour_adjusted_df with location_ID\n",
    "local_hour_adjusted_df.head()\n",
    "local_hour_adjusted_df.info()\n",
    "var_with_id_path = os.path.join(summary_dir, 'local_hour_adjusted_variables_with_location_ID.feather')\n",
    "local_hour_adjusted_df.to_feather(var_with_id_path)\n",
    "'''"
   ],
   "id": "fc4868808fc0ef3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49ea995b",
   "metadata": {},
   "source": [
    "##  Step 3.2 compute average based on local hour"
   ]
  },
  {
   "cell_type": "code",
   "id": "447d0ccd",
   "metadata": {},
   "source": [
    "# os.environ[\"PROJ_LIB\"] = \"/home/jguo/anaconda3/envs/I2000/share/proj\"\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Group by 'lat', 'lon', and 'local_hour', then calculate the mean for 'UHI_diff'\n",
    "# Ensure grouped data is sorted by 'lat' and 'lon' before pivoting\n",
    "var_diff_by_localhour = local_hour_adjusted_df.groupby(['lat', 'lon', 'local_hour'])[['UHI_diff', 'UWBI_diff']].mean().reset_index().sort_values(by=['lat', 'lon', 'local_hour'])\n",
    "\n",
    "var_diff_by_localhour\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "var_diff_by_localhour.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3cfbaf16ab84993",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29f22336",
   "metadata": {},
   "source": [
    "# 4: Plot and Explore"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1: Plot the UHI_diff and UWBI by local hour",
   "id": "979fa43597b06151"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group the DataFrame by 'local_hour' and calculate the mean of 'UHI_diff' and 'UWBI_diff'\n",
    "grouped_df = local_hour_adjusted_df.groupby('local_hour')[['UHI_diff', 'UWBI_diff']].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot UHI_diff\n",
    "plt.plot(grouped_df.index, grouped_df['UHI_diff'], marker='o', label='UHI_diff')\n",
    "\n",
    "# Plot UWBI_diff\n",
    "plt.plot(grouped_df.index, grouped_df['UWBI_diff'], marker='s', label='UWBI_diff')\n",
    "\n",
    "plt.title('Mean UHI and UWBI Difference by Local Hour')\n",
    "plt.xlabel('Local Hour')\n",
    "plt.ylabel('Mean Difference')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b42fd29f7f6fbd17",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the map drawing function for subplots\n",
    "def draw_map_subplot(m, ax):\n",
    "    m.drawcoastlines(linewidth=0.5, ax=ax)\n",
    "    m.drawcountries(linewidth=0.5, ax=ax)\n",
    "    m.fillcontinents(color='coral', lake_color='aqua', alpha=0.3, ax=ax)\n",
    "    m.drawmapboundary(fill_color='aqua', ax=ax)\n",
    "    m.drawparallels(np.arange(-90., 91., 30.), labels=[1, 0, 0, 0], fontsize=10, ax=ax)\n",
    "    m.drawmeridians(np.arange(-180., 181., 60.), labels=[0, 0, 0, 1], fontsize=10, ax=ax)\n",
    "\n",
    "# Find global min and max of UHI_diff\n",
    "global_min = var_diff_by_localhour['UHI_diff'].min()\n",
    "global_max = var_diff_by_localhour['UHI_diff'].max()\n",
    "\n",
    "# Calculate the number of rows needed for the subplots\n",
    "n_hours = len(var_diff_by_localhour['local_hour'].unique())\n",
    "n_rows = (n_hours + 2) // 3  # Adding 2 to ensure rounding up if there's a remainder\n",
    "\n",
    "# Create a figure to hold all subplots\n",
    "fig, axs = plt.subplots(n_rows, 3, figsize=(18, n_rows * 6), constrained_layout=True)\n",
    "\n",
    "# Iterate through each local_hour to create subplots\n",
    "for i, hour in enumerate(var_diff_by_localhour['local_hour'].unique()):\n",
    "    row, col = divmod(i, 3)\n",
    "    ax = axs[row, col] if n_rows > 1 else axs[col]  # Adjust for the case of a single row\n",
    "\n",
    "    # Setup the Basemap\n",
    "    m = Basemap(projection='cyl', resolution='l', lat_0=0, lon_0=0, ax=ax)\n",
    "\n",
    "    draw_map_subplot(m, ax)\n",
    "\n",
    "    # Filter data for the current hour\n",
    "    df_hour = var_diff_by_localhour[var_diff_by_localhour['local_hour'] == hour]\n",
    "\n",
    "    # Scatter UHI_diff data\n",
    "    x, y = m(df_hour['lon'].values, df_hour['lat'].values)\n",
    "    # Set vmin and vmax to the global min/max values\n",
    "    sc = m.scatter(x, y, c=df_hour['UHI_diff'], vmin=global_min, vmax=global_max, cmap='hot', marker='o', edgecolor='none', alpha=0.75, ax=ax)\n",
    "\n",
    "    ax.set_title(f'UHI Difference Map at Local Hour {hour}')\n",
    "\n",
    "    # Add color bar to each subplot\n",
    "    plt.colorbar(sc, ax=ax, fraction=0.046, pad=0.04, label='UHI_diff')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n"
   ],
   "metadata": {},
   "id": "bc9c690b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "I have some understanding about UHI:\n",
    "1. Diurnal Cycle of Solar Radiation: During the daytime, solar radiation is the primary source of heat for both urban and rural areas. However, urban surfaces, with their lower albedo and higher heat capacity, tend to absorb and store more solar radiation than rural surfaces. This leads to a smaller UHI effect during the day. At night, the absence of solar radiation allows the stored heat in urban areas to be gradually released, resulting in a stronger UHI effect at night.\n",
    "2. Boundary Layer Dynamics: The atmospheric boundary layer, the layer of air closest to the Earth's surface, plays a crucial role in heat dissipation. During the day, the boundary layer is typically deeper and more turbulent, promoting greater mixing and heat exchange between the surface and the atmosphere. This can help to mitigate the UHI effect. At night, the boundary layer becomes shallower and more stable, trapping heat near the surface and intensifying the UHI effect.\n",
    "\n",
    "I need to better understand why the synergy is also showing a diurnal cycle."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7e731943da98485"
  },
  {
   "cell_type": "markdown",
   "source": "##  4.2: Koppen Geiger Climate Analysis",
   "metadata": {
    "collapsed": false
   },
   "id": "6f52ed687cc6ac5e"
  },
  {
   "cell_type": "markdown",
   "source": "###  4.2.1: load the koppen geiger map and legend",
   "metadata": {
    "collapsed": false
   },
   "id": "9a66ce85491ac5b"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the NetCDF file\n",
    "ds_koppen_map = xr.open_dataset('/home/jguo/other_projects/1991_2020/koppen_geiger_0p5.nc')\n",
    "#ds_koppen_map.kg_class.min()\n",
    "\n",
    "# Load the Koppen Geiger Legend Excel file\n",
    "kg_legend = pd.read_excel('/home/jguo/research/hw_global/Data/KoppenGeigerLegend.xlsx', engine='openpyxl')\n",
    "kg_legend"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94a04f06fb017e15",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "###  4.2.2: Find the nearest Koppen Geiger class for each grid cell",
   "metadata": {
    "collapsed": false
   },
   "id": "4dcc00479705bdd4"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Convert latitudes and longitudes from the NetCDF dataset to numpy arrays\n",
    "latitudes = ds_koppen_map['lat'].values\n",
    "longitudes = ds_koppen_map['lon'].values\n",
    "\n",
    "# Flatten the latitudes, longitudes, and kg_class for easier manipulation\n",
    "lat_flat = np.repeat(latitudes, len(longitudes))\n",
    "lon_flat = np.tile(longitudes, len(latitudes))\n",
    "kg_class_flat = ds_koppen_map['kg_class'].values.flatten()\n",
    "\n",
    "# Filter out the zero kg_class values\n",
    "non_zero_indices = kg_class_flat > 0\n",
    "lat_flat_non_zero = lat_flat[non_zero_indices]\n",
    "lon_flat_non_zero = lon_flat[non_zero_indices]\n",
    "kg_class_flat_non_zero = kg_class_flat[non_zero_indices]\n",
    "\n",
    "# Function to find the nearest non-zero kg_class for given lat and lon\n",
    "def find_nearest_non_zero_kg_class(lat, lon):\n",
    "    distances = np.sqrt((lat_flat_non_zero - lat)**2 + (lon_flat_non_zero - lon)**2)\n",
    "    nearest_index = np.argmin(distances)\n",
    "    return kg_class_flat_non_zero[nearest_index]\n",
    "\n",
    "# Vectorize the function to apply it efficiently to arrays\n",
    "vec_find_nearest_non_zero_kg_class = np.vectorize(find_nearest_non_zero_kg_class)\n",
    "\n",
    "# Apply the vectorized function to each lat and lon in var_diff_by_localhour\n",
    "var_diff_by_localhour['KG_ID'] = vec_find_nearest_non_zero_kg_class(var_diff_by_localhour['lat'].values, var_diff_by_localhour['lon'].values)\n",
    "var_diff_by_localhour.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37f7b7ec6dbbc6d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "###  4.2.3: Plot the UHI_diff by local hour for each Koppen Geiger class",
   "metadata": {
    "collapsed": false
   },
   "id": "9cb68449c9414c"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Calculate average UHI_diff by local_hour for each KG class\n",
    "avg_uhi_by_hour_and_kg = var_diff_by_localhour.groupby(['KG_ID', 'local_hour'])['UHI_diff'].mean().reset_index()\n",
    "# Map KG classes to their descriptions\n",
    "kg_map = dict(zip(kg_legend['ID'], kg_legend['KGClass']))\n",
    "# Plotting\n",
    "import textwrap\n",
    "\n",
    "# Define the number of graphs you want in each row\n",
    "graphs_per_row = 4  # You can change this number to your preference\n",
    "\n",
    "# Find the global minimum and maximum UHI_diff values for consistent y-axis limits\n",
    "global_min_uhi = avg_uhi_by_hour_and_kg['UHI_diff'].min()\n",
    "global_max_uhi = avg_uhi_by_hour_and_kg['UHI_diff'].max()\n",
    "\n",
    "# Unique KG IDs\n",
    "unique_kg_ids = avg_uhi_by_hour_and_kg['KG_ID'].unique()\n",
    "\n",
    "# Number of KG IDs\n",
    "n_kg_ids = len(unique_kg_ids)\n",
    "\n",
    "# Calculate the number of rows needed\n",
    "n_rows = (n_kg_ids + graphs_per_row - 1) // graphs_per_row  # Ensures rounding up\n",
    "\n",
    "# Loop through each KG ID\n",
    "for i, kg_id in enumerate(unique_kg_ids):\n",
    "    # Create a new figure at the start and after every 'graphs_per_row' plots\n",
    "    if i % graphs_per_row == 0:\n",
    "        plt.figure(figsize=(5 * graphs_per_row, 5 * n_rows))  # Adjust figure size as needed\n",
    "    # Select the subplot position\n",
    "    plt.subplot(n_rows, graphs_per_row, i % graphs_per_row + 1)\n",
    "\n",
    "    # Extract the subset of data for the current KG ID\n",
    "    subset = avg_uhi_by_hour_and_kg[avg_uhi_by_hour_and_kg['KG_ID'] == kg_id]\n",
    "\n",
    "    # Plot the data\n",
    "    plt.plot(subset['local_hour'], subset['UHI_diff'], marker='o')\n",
    "\n",
    "    # Wrap the title text\n",
    "    title_text = f'KG Class {kg_id}: {kg_map.get(kg_id, \"Unknown\")} - Average Hourly UHI_diff'\n",
    "    wrapped_title = textwrap.fill(title_text, width=40)  # Adjust 'width' as needed\n",
    "\n",
    "    plt.title(wrapped_title)\n",
    "    plt.xlabel('Local Hour')\n",
    "    plt.ylabel('Average UHI_diff')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Set the same y-axis limits for all plots\n",
    "    plt.ylim(global_min_uhi, global_max_uhi)\n",
    "\n",
    "    # Show the figure after every 'graphs_per_row' plots or on the last plot\n",
    "    if (i % graphs_per_row == graphs_per_row - 1) or (i == n_kg_ids - 1):\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c093ac73df470f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "97e213a8e068fe1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  4.2.4: Main group analysis: Aggregate data based on the main group only.",
   "id": "c806e8f82e3cc42f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The kg_legend data frame has a KGClass column, which has values for KG classification main group and subgroup, separated by a comma.\n",
    "# Extract main group from KGClass\n",
    "kg_legend['KGMainGroup'] = kg_legend['KGClass'].apply(lambda x: x.split(',')[0].strip())\n",
    "\n",
    "# Map KG IDs to their main groups\n",
    "kg_main_group_map = dict(zip(kg_legend['ID'], kg_legend['KGMainGroup']))\n",
    "kg_main_group_map"
   ],
   "id": "e9c3274066336f4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "set(kg_main_group_map.values())",
   "id": "f2a3f88b0b3980",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract main group from KGClass\n",
    "kg_legend['KGMainGroup'] = kg_legend['KGClass'].apply(lambda x: x.split(',')[0].strip())\n",
    "\n",
    "# Map KG IDs to their main groups\n",
    "kg_main_group_map = dict(zip(kg_legend['ID'], kg_legend['KGMainGroup']))\n",
    "\n",
    "# Create a dictionary to map main group values to their minimum IDs\n",
    "main_group_min_id = {}\n",
    "for kg_id, main_group in kg_main_group_map.items():\n",
    "    if main_group not in main_group_min_id:\n",
    "        main_group_min_id[main_group] = kg_id\n",
    "    else:\n",
    "        main_group_min_id[main_group] = min(main_group_min_id[main_group], kg_id)\n",
    "\n",
    "# Get the unique main group values sorted by their minimum IDs\n",
    "sorted_main_groups = sorted(set(kg_main_group_map.values()), key=lambda x: main_group_min_id[x])\n",
    "\n",
    "# Add main group to var_diff_by_localhour\n",
    "var_diff_by_localhour['KGMainGroup'] = var_diff_by_localhour['KG_ID'].map(kg_main_group_map)\n",
    "\n",
    "# Calculate average UHI_diff and UWBI_diff by local_hour for each KG main group\n",
    "avg_diff_by_hour_and_main_group = var_diff_by_localhour.groupby(['KGMainGroup', 'local_hour'])[['UHI_diff', 'UWBI_diff']].mean().reset_index()\n",
    "\n",
    "# Find the global minimum and maximum values for UHI_diff and UWBI_diff\n",
    "min_uhi_diff = avg_diff_by_hour_and_main_group['UHI_diff'].min()\n",
    "max_uhi_diff = avg_diff_by_hour_and_main_group['UHI_diff'].max()\n",
    "min_UWBI_diff = avg_diff_by_hour_and_main_group['UWBI_diff'].min()\n",
    "max_UWBI_diff = avg_diff_by_hour_and_main_group['UWBI_diff'].max()"
   ],
   "id": "83009d1b37ae44b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Determine the number of rows needed for subplots\n",
    "n_rows = (len(sorted_main_groups) + 3) // 4\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(n_rows, 4, figsize=(20, 6*n_rows), squeeze=False)\n",
    "\n",
    "# Plotting\n",
    "for i, main_group in enumerate(sorted_main_groups):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "\n",
    "    subset = avg_diff_by_hour_and_main_group[avg_diff_by_hour_and_main_group['KGMainGroup'] == main_group]\n",
    "\n",
    "    axs[row, col].plot(subset['local_hour'], subset['UHI_diff'], marker='o', label='UHI_diff')\n",
    "    axs[row, col].plot(subset['local_hour'], subset['UWBI_diff'], marker='s', label='UWBI_diff')\n",
    "\n",
    "    # Create font dictionaries for the title\n",
    "    title_font = {'size': 14, 'weight': 'normal'}\n",
    "    main_group_font = {'size': 16, 'weight': 'bold'}\n",
    "\n",
    "    # Create the title with the main group in bold and bigger font\n",
    "    axs[row, col].set_title(f'KG Main Group:', fontdict=title_font)\n",
    "    axs[row, col].text(0.5, 1.05, main_group, fontdict=main_group_font, transform=axs[row, col].transAxes, ha='center', va='bottom')\n",
    "\n",
    "    axs[row, col].set_xlabel('Local Hour')\n",
    "    axs[row, col].set_ylabel('Average Difference')\n",
    "    axs[row, col].grid(True)\n",
    "    axs[row, col].legend()\n",
    "\n",
    "    # Set the same y-axis limits for all subplots\n",
    "    # axs[row, col].set_ylim(min(min_uhi_diff, min_UWBI_diff), max(max_uhi_diff, max_UWBI_diff))\n",
    "    axs[row, col].set_ylim(-0.75, 0.75)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for i in range(len(sorted_main_groups), n_rows * 4):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    fig.delaxes(axs[row, col])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust the top spacing\n",
    "plt.suptitle('Average Hourly UHI_diff and UWBI_diff by KG Main Group', size=20, weight='bold', y=0.99)  # Add an overall title\n",
    "\n",
    "plt.show()"
   ],
   "id": "cdd895f8fa7dec0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Next Steps: Statistical Analysis and Interpretation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4daa1570cc9e8d5c"
  },
  {
   "cell_type": "markdown",
   "source": "## 5.1: Statistical Analysis: LHS UHI_diff or UWBI_diff. RHS KG_ID (major and sub categories), day and night (we are going to collapse the hours into day and night)",
   "metadata": {
    "collapsed": false
   },
   "id": "241b381f2b80494f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2: Try using UHI_hour on the LHS and perform similar analysis as above.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be695cf334c65b05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3: Coastline analysis. (optional because Kopphen Geiger zones has in a way already capture the coastal effect to me) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3593e02695990497"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#   Miscalanous items"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8590a7c15580328f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## group by north south hemisphere"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a2bfe88e76bdfdb"
  },
  {
   "cell_type": "code",
   "source": [
    "var_diff_by_localhour.groupby(lambda x: (var_diff_by_localhour.loc[x, 'lat'] > 0, var_diff_by_localhour.loc[x, 'local_hour']))['UHI_diff'].mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5adcb30c2eb21982",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
